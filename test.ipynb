{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연산그래프 구조 변환, 배열 연산 테스트 [[참조](https://velog.io/@pre_f_86/series/PyTorch-AutoGrad%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80)]\n",
    "\n",
    "- Pytorch의 연산 로직에 대한 이해와 비슷하게 작동하도록 구현\n",
    "\n",
    "- Param 객체 내의 Data가 숫자, 소수점 등의 Scalar 데이터 타입이 아닌 배열(Numpy) 객체를 활용하여 Matrix 데이터를 담을 수 있도록 구현\n",
    "\n",
    "    - 숫자, 소수점을 담는 경우에는 너무 많은 객체가 생성되어 연산량, 메모리 사용량 등의 증가를 해결 하고자 함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src as my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.5, -2.5, -2.5, -2.5, -2.5, -2.5, -2.5, -2.5, -2.5, -2.5]),\n",
       " array([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val1 = my.Param(np.zeros((10)), requires_grad=True)\n",
    "val2 = my.Param(np.ones((10)), requires_grad=True)\n",
    "\n",
    "out = abs(-((val1*val2)*5**2/10-1))\n",
    "summed = 0\n",
    "for val in out:\n",
    "    summed += val\n",
    "summed.backward()\n",
    "val1.grad, val2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.5000, -2.5000, -2.5000, -2.5000, -2.5000, -2.5000, -2.5000, -2.5000,\n",
       "         -2.5000, -2.5000]),\n",
       " tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val1 = torch.zeros((10), requires_grad=True)\n",
    "val2 = torch.ones((10), requires_grad=True)\n",
    "\n",
    "out = abs(-((val1*val2)*5**2/10-1))\n",
    "summed = 0\n",
    "for val in out:\n",
    "    summed += val\n",
    "summed.backward()\n",
    "val1.grad, val2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인덱싱(Get, Set) 그래디언트 테스트\n",
    "\n",
    "- val1 : 연산 테스트, Leaf 노드까지 그래디언트가 잘 전달 되는지 확인\n",
    "\n",
    "- val2 : val1과 동일\n",
    "\n",
    "- val3 : Set 연산, Get 연산 테스트\n",
    "\n",
    "- val4 : 중첩되는 Set 연산에 대한 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(val1, val2, val3, val4):\n",
    "    out1 = val1+5\n",
    "\n",
    "    out2 = out1*val2\n",
    "\n",
    "    out2[2:7] = val3[:5]\n",
    "\n",
    "    out2[1:3] = val4\n",
    "\n",
    "    out3 = 0\n",
    "    for i in range(out2.data.shape[0]):\n",
    "        out3 = (out3 + out2[i])*5\n",
    "    out3.backward()\n",
    "    print(val1.grad)\n",
    "    print(val2.grad)\n",
    "    print(val3.grad)\n",
    "    print(val4.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.765625e+06 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 1.250000e+02 2.500000e+01 5.000000e+00]\n",
      "[4.8828125e+07 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 6.2500000e+02 1.2500000e+02 2.5000000e+01]\n",
      "[    0. 78125. 15625.  3125.   625.     0.     0.     0.     0.     0.]\n",
      "[1953125.  390625.]\n"
     ]
    }
   ],
   "source": [
    "val1 = my.Param(np.zeros(10), requires_grad=True)\n",
    "val2 = my.Param(np.ones(10), requires_grad=True)\n",
    "val3 = my.Param(np.ones(10), requires_grad=True)\n",
    "val4 = my.Param(np.ones(2), requires_grad=True)\n",
    "\n",
    "test(val1, val2, val3, val4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.7656e+06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.2500e+02, 2.5000e+01, 5.0000e+00])\n",
      "tensor([4.8828e+07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.2500e+02, 1.2500e+02, 2.5000e+01])\n",
      "tensor([    0., 78125., 15625.,  3125.,   625.,     0.,     0.,     0.,     0.,\n",
      "            0.])\n",
      "tensor([1953125.,  390625.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val1 = torch.zeros(10, requires_grad=True)\n",
    "val2 = torch.ones(10, requires_grad=True)\n",
    "val3 = torch.ones(10, requires_grad=True)\n",
    "val4 = torch.ones(2, requires_grad=True)\n",
    "\n",
    "test(val1, val2, val3, val4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이어 연산 테스트\n",
    "\n",
    "※ 브로드캐스팅으로 인해 역전파된 그래디언트의 차원이 맞지 않는 현상 발견 (Layer의 Bias 부분)\n",
    "\n",
    "- Linear 연산 이후 계산된 그래디언트 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src as my\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class mymodel(my.layers.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = my.layers.Linear(2,4,bias=True)\n",
    "        self.l2 = my.layers.Linear(4,4,bias=True)\n",
    "        self.l3 = my.layers.Linear(4,4,bias=True)\n",
    "        self.l4 = my.layers.Linear(4,1,bias=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.l4(out)\n",
    "        ret = 0\n",
    "\n",
    "        for o in out:\n",
    "            ret = ret + o\n",
    "        return ret\n",
    "model = mymodel()\n",
    "x = my.Param(np.ones((5,2)))\n",
    "\n",
    "out = model(x)\n",
    "out.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node (Data:[1065.], requrired_grad:True) (1,)\n",
      "[[80. 80. 80. 80.]\n",
      " [80. 80. 80. 80.]]\n",
      "[[16. 16. 16. 16.]\n",
      " [16. 16. 16. 16.]\n",
      " [16. 16. 16. 16.]\n",
      " [16. 16. 16. 16.]\n",
      " [16. 16. 16. 16.]]\n",
      "[[60. 60. 60. 60.]\n",
      " [60. 60. 60. 60.]\n",
      " [60. 60. 60. 60.]\n",
      " [60. 60. 60. 60.]]\n",
      "[[4. 4. 4. 4.]\n",
      " [4. 4. 4. 4.]\n",
      " [4. 4. 4. 4.]\n",
      " [4. 4. 4. 4.]\n",
      " [4. 4. 4. 4.]]\n",
      "[[65. 65. 65. 65.]\n",
      " [65. 65. 65. 65.]\n",
      " [65. 65. 65. 65.]\n",
      " [65. 65. 65. 65.]]\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "[[265.]\n",
      " [265.]\n",
      " [265.]\n",
      " [265.]]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import src as my\n",
    "model = mymodel()\n",
    "x = my.Param(np.ones((5,2)))\n",
    "\n",
    "out = model(x)\n",
    "out.backward()\n",
    "\n",
    "print()\n",
    "print(out,out.shape)\n",
    "print(model.l1.weight.grad)\n",
    "print(model.l1.bias.grad)\n",
    "print(model.l2.weight.grad)\n",
    "print(model.l2.bias.grad)\n",
    "print(model.l3.weight.grad)\n",
    "print(model.l3.bias.grad)\n",
    "print(model.l4.weight.grad)\n",
    "print(model.l4.bias.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1065.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class mymodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(2,4, bias=True)\n",
    "        self.l2 = nn.Linear(4,4, bias=True)\n",
    "        self.l3 = nn.Linear(4,4, bias=True)\n",
    "        self.l4 = nn.Linear(4,1, bias=True)\n",
    "    \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.children():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.constant_(layer.weight, 1)  \n",
    "                if layer.bias is not None:\n",
    "                    nn.init.constant_(layer.bias, 1) \n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.l4(out)\n",
    "        ret = 0\n",
    "        for o in out:\n",
    "            ret = ret + o\n",
    "        return ret\n",
    "    \n",
    "\n",
    "model = mymodel()\n",
    "x = torch.ones((5,2))\n",
    "out = model(x)\n",
    "out.backward()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[80., 80.],\n",
      "        [80., 80.],\n",
      "        [80., 80.],\n",
      "        [80., 80.]])\n",
      "tensor([80., 80., 80., 80.])\n",
      "tensor([[60., 60., 60., 60.],\n",
      "        [60., 60., 60., 60.],\n",
      "        [60., 60., 60., 60.],\n",
      "        [60., 60., 60., 60.]])\n",
      "tensor([20., 20., 20., 20.])\n",
      "tensor([[65., 65., 65., 65.],\n",
      "        [65., 65., 65., 65.],\n",
      "        [65., 65., 65., 65.],\n",
      "        [65., 65., 65., 65.]])\n",
      "tensor([5., 5., 5., 5.])\n",
      "tensor([[265., 265., 265., 265.]])\n",
      "tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "print(model.l1.weight.grad)\n",
    "print(model.l1.bias.grad)\n",
    "print(model.l2.weight.grad)\n",
    "print(model.l2.bias.grad)\n",
    "print(model.l3.weight.grad)\n",
    "print(model.l3.bias.grad)\n",
    "print(model.l4.weight.grad)\n",
    "print(model.l4.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서로 다른 차원을 가진 객체에 대한 역전파 테스트 [[참조](https://numpy.org/doc/stable/user/basics.broadcasting.html)]\n",
    "\n",
    "- (5, 1) 과 (1)의 차원을 가진 두 객체 사이의 연산\n",
    "\n",
    "- (5, 1) 과 (1, 5)의 차원을 가진 두 객체 사이의 연산\n",
    "\n",
    "**Numpy 브로드캐스팅 규칙**\n",
    "\n",
    "1. 두 차원의 길이가 맞지 않는 경우 길이가 맞을 때까지 작은 차원의 앞에 1을 붙임\n",
    "\n",
    "    - (5, 2, 5) + (5,) -> (5, 2, 5) + (1, 1, 5)\n",
    "\n",
    "2. 차원이 1인 경우 각 위치에 맞는 차원만큼 배열 복사\n",
    "\n",
    "    - (5, 2, 5) + (1, 1, 5) -> (5, 2, 5) + (5, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src as my\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = my.Param(np.zeros((1, 5)), requires_grad=True)\n",
    "tmp2 = my.Param(np.ones((5, 1)), requires_grad=True)\n",
    "out = tmp1*tmp2\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5., 5., 5., 5., 5.]]),\n",
       " (1, 5),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " (5, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1.grad, tmp1.grad.shape, tmp2.grad, tmp2.grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 테스트\n",
    "\n",
    "- 가중치를 1이 아닌 He Init을 사용하여 초기화\n",
    "\n",
    "- Adam 구현\n",
    "\n",
    "- ReLU 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src as my\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    x[x<0] = 0\n",
    "    return x\n",
    "\n",
    "class mymodel(my.layers.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = my.layers.Linear(2,16,bias=True)\n",
    "        self.l2 = my.layers.Linear(16,16,bias=True)\n",
    "        self.l3 = my.layers.Linear(16,16,bias=True)\n",
    "        self.l4 = my.layers.Linear(16,1,bias=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = relu(out)\n",
    "        out = self.l3(out)\n",
    "        out = relu(out)\n",
    "        out = self.l4(out)\n",
    "        return out\n",
    "\n",
    "x = my.Param(np.stack([np.arange(100), np.arange(100)], 1))/100\n",
    "y = my.Param(np.arange(100).reshape(-1, 1))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:[0.18300367], requrired_grad:True\n",
      "Data:[0.04558312], requrired_grad:True\n",
      "Data:[0.00253195], requrired_grad:True\n",
      "Data:[2.43981414e-06], requrired_grad:True\n",
      "Data:[0.00052742], requrired_grad:True\n",
      "Data:[0.00049233], requrired_grad:True\n",
      "Data:[0.00027985], requrired_grad:True\n",
      "Data:[0.0001116], requrired_grad:True\n",
      "Data:[3.78963245e-05], requrired_grad:True\n",
      "Data:[1.0044037e-05], requrired_grad:True\n",
      "Data:[1.74961075e-06], requrired_grad:True\n",
      "Data:[7.58300889e-08], requrired_grad:True\n",
      "Data:[3.37215609e-08], requrired_grad:True\n",
      "Data:[8.47882185e-08], requrired_grad:True\n",
      "Data:[6.00794388e-08], requrired_grad:True\n",
      "Data:[2.55156315e-08], requrired_grad:True\n",
      "Data:[7.84502031e-09], requrired_grad:True\n",
      "Data:[1.72523721e-09], requrired_grad:True\n",
      "Data:[2.06079571e-10], requrired_grad:True\n",
      "Data:[1.89906463e-11], requrired_grad:True\n",
      "Data:[4.19445674e-11], requrired_grad:True\n",
      "Data:[3.81100717e-11], requrired_grad:True\n",
      "Data:[1.73545469e-11], requrired_grad:True\n",
      "Data:[4.54230245e-12], requrired_grad:True\n",
      "Data:[5.50345816e-13], requrired_grad:True\n",
      "Data:[3.15865218e-14], requrired_grad:True\n",
      "Data:[7.30346324e-14], requrired_grad:True\n",
      "Data:[6.5025515e-14], requrired_grad:True\n",
      "Data:[2.92746985e-14], requrired_grad:True\n",
      "Data:[7.75968502e-15], requrired_grad:True\n",
      "Data:[9.63312375e-16], requrired_grad:True\n",
      "Data:[7.10820029e-17], requrired_grad:True\n",
      "Data:[1.90607568e-16], requrired_grad:True\n",
      "Data:[1.50178713e-16], requrired_grad:True\n",
      "Data:[5.17655645e-17], requrired_grad:True\n",
      "Data:[6.60867552e-18], requrired_grad:True\n",
      "Data:[1.45704003e-20], requrired_grad:True\n",
      "Data:[9.70548923e-19], requrired_grad:True\n",
      "Data:[8.07234777e-19], requrired_grad:True\n",
      "Data:[2.45826265e-19], requrired_grad:True\n",
      "Data:[2.50547088e-20], requrired_grad:True\n",
      "Data:[3.01387854e-21], requrired_grad:True\n",
      "Data:[7.41634918e-21], requrired_grad:True\n",
      "Data:[4.19604187e-21], requrired_grad:True\n",
      "Data:[9.32770999e-22], requrired_grad:True\n",
      "Data:[5.97603215e-23], requrired_grad:True\n",
      "Data:[5.53897926e-23], requrired_grad:True\n",
      "Data:[5.63407935e-23], requrired_grad:True\n",
      "Data:[1.86311188e-23], requrired_grad:True\n",
      "Data:[1.73209692e-24], requrired_grad:True\n",
      "Data:[4.63253853e-25], requrired_grad:True\n",
      "Data:[7.72477141e-25], requrired_grad:True\n",
      "Data:[3.01141269e-25], requrired_grad:True\n",
      "Data:[2.76651006e-26], requrired_grad:True\n",
      "Data:[6.35053916e-27], requrired_grad:True\n",
      "Data:[1.22700739e-26], requrired_grad:True\n",
      "Data:[4.16050411e-27], requrired_grad:True\n",
      "Data:[2.1835075e-28], requrired_grad:True\n",
      "Data:[1.96357484e-28], requrired_grad:True\n",
      "Data:[1.80544926e-28], requrired_grad:True\n",
      "Data:[6.44216252e-29], requrired_grad:True\n",
      "Data:[2.04528525e-29], requrired_grad:True\n",
      "Data:[4.23442797e-30], requrired_grad:True\n",
      "Data:[4.05138533e-31], requrired_grad:True\n",
      "Data:[6.7333487e-31], requrired_grad:True\n",
      "Data:[4.04923792e-31], requrired_grad:True\n",
      "Data:[2.40358856e-31], requrired_grad:True\n",
      "Data:[2.3395899e-31], requrired_grad:True\n",
      "Data:[2.2859335e-31], requrired_grad:True\n",
      "Data:[2.08455826e-31], requrired_grad:True\n",
      "Data:[2.05216412e-31], requrired_grad:True\n",
      "Data:[2.52236066e-31], requrired_grad:True\n",
      "Data:[2.56717705e-31], requrired_grad:True\n",
      "Data:[2.10333608e-31], requrired_grad:True\n",
      "Data:[2.02470036e-31], requrired_grad:True\n",
      "Data:[2.17095548e-31], requrired_grad:True\n",
      "Data:[2.1648888e-31], requrired_grad:True\n",
      "Data:[2.36320181e-31], requrired_grad:True\n",
      "Data:[2.34575288e-31], requrired_grad:True\n",
      "Data:[2.36056328e-31], requrired_grad:True\n",
      "Data:[2.29978093e-31], requrired_grad:True\n",
      "Data:[2.33275285e-31], requrired_grad:True\n",
      "Data:[2.27670829e-31], requrired_grad:True\n",
      "Data:[1.78056948e-31], requrired_grad:True\n",
      "Data:[1.70983007e-31], requrired_grad:True\n",
      "Data:[1.62528175e-31], requrired_grad:True\n",
      "Data:[1.61780914e-31], requrired_grad:True\n",
      "Data:[1.63329362e-31], requrired_grad:True\n",
      "Data:[1.7718065e-31], requrired_grad:True\n",
      "Data:[1.7167249e-31], requrired_grad:True\n",
      "Data:[1.64122845e-31], requrired_grad:True\n",
      "Data:[1.70416784e-31], requrired_grad:True\n",
      "Data:[1.57711424e-31], requrired_grad:True\n",
      "Data:[1.60640763e-31], requrired_grad:True\n",
      "Data:[1.59878095e-31], requrired_grad:True\n",
      "Data:[1.61869507e-31], requrired_grad:True\n",
      "Data:[1.78309245e-31], requrired_grad:True\n",
      "Data:[1.69602115e-31], requrired_grad:True\n",
      "Data:[1.68144186e-31], requrired_grad:True\n",
      "Data:[1.67658852e-31], requrired_grad:True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data:[1000.], requrired_grad:True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = mymodel()\n",
    "optim = my.optimizers.Adam(params=model.parameters(),lr=1e-3)\n",
    "for i in range(1000):\n",
    "    out = model(x)\n",
    "    \n",
    "    loss = (out-y)**2\n",
    "\n",
    "    loss_mean = 0\n",
    "    for l in loss:\n",
    "        loss_mean = loss_mean + l/100\n",
    "\n",
    "    \n",
    "    loss_mean.backward()\n",
    "    optim.update()\n",
    "    optim.zero_grad()\n",
    "    if (i%10==0):\n",
    "        print(loss_mean)  \n",
    "model([1000,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주요 배열 연산 테스트\n",
    "\n",
    "※ 이 과정에서 Param 객체 생성시 Numpy 스칼라인 경우에는 허용되지 않는 경우(버그) 수정\n",
    "\n",
    "- Sum(), Mean() 연산 : 그래디언트 테스트, 연산 결과 테스트\n",
    "\n",
    "- Reshape, Stack, Concat 연산 : 그래디언트 테스트, 연산 결과 테스트\n",
    "\n",
    "- aranage, ones, zeros, full, ~_like 연산 : 결과 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src as my\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) [1, 2, 1]\n",
      "Data:[594 837], requrired_grad:True (2,) (54,)\n",
      "[4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5\n",
      " 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5\n",
      " 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5]\n"
     ]
    }
   ],
   "source": [
    "arr = my.arange(54, requires_grad=True)\n",
    "arr2 = arr.reshape((3, 2, 9))\n",
    "out = arr2.sum((2, 0))\n",
    "(out.mean()*9).backward()\n",
    "print(out, out.shape, arr.grad.shape)\n",
    "print(arr.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([594., 837.], grad_fn=<SumBackward1>) torch.Size([2]) torch.Size([54])\n",
      "tensor([4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000,\n",
      "        4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000,\n",
      "        4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000,\n",
      "        4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000,\n",
      "        4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000,\n",
      "        4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000])\n"
     ]
    }
   ],
   "source": [
    "arr = torch.arange(54, dtype=torch.float32, requires_grad=True)\n",
    "arr2 = arr.reshape((3, 2, 9))\n",
    "out = arr2.sum((2, 0))\n",
    "(out.mean()*9).backward()\n",
    "print(out, out.shape, arr.grad.shape)\n",
    "print(arr.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[2., 2., 2.]]]), array([[[2., 2., 2.]]]), array([[[2., 2., 2.]]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = my.ones((1,1,3), requires_grad=True)\n",
    "arr2 = my.zeros((1,1,3), requires_grad=True)\n",
    "arr3 = my.full((1,1,3), 3, requires_grad=True)\n",
    "stack = my.stack([arr1, arr2, arr3], 0)\n",
    "concat = my.concat([arr1, arr2, arr3], 0)\n",
    "stack.sum().backward()\n",
    "concat.sum().backward()\n",
    "\n",
    "arr1.grad, arr2.grad, arr3.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2., 2., 2.]]]), tensor([[[2., 2., 2.]]]), tensor([[[2., 2., 2.]]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = torch.ones((1,1,3), requires_grad=True)\n",
    "arr2 = torch.zeros((1,1,3), requires_grad=True)\n",
    "arr3 = torch.full((1,1,3), 3, dtype=torch.float32, requires_grad=True)\n",
    "stack = torch.stack([arr1, arr2, arr3], 0)\n",
    "concat = torch.concat([arr1, arr2, arr3], 0)\n",
    "stack.sum().backward()\n",
    "concat.sum().backward()\n",
    "\n",
    "arr1.grad, arr2.grad, arr3.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution 연산 테스트\n",
    "\n",
    "- Torch와의 Gradient, Output 비교\n",
    "\n",
    "- Padding(0, 1, 2) 에서의 비교\n",
    "\n",
    "- Kernel_size (2, 3) 에서 비교\n",
    "\n",
    "- Stride (1, 2) 에서 비교\n",
    "\n",
    "- Non-Batch, Batch 에서 비교\n",
    "\n",
    "- Backward 단계에서 연산 시간이 오래 걸려 Convolution grad function 구현 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src as my\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data:13419.0, requrired_grad:True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class mymodel(my.layers.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = my.layers.Conv1d(2, 4, 3, 2, padding=2, bias=True)\n",
    "        self.l2 = my.layers.Conv1d(4, 4, 3, 2, padding=2, bias=True)\n",
    "        self.l3 = my.layers.Conv1d(4, 4, 3, 2, padding=2, bias=True)\n",
    "        self.l4 = my.layers.Conv1d(4, 1, 3, 2, padding=2, bias=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.l4(out)\n",
    "        print(out.shape)\n",
    "        return out.sum()\n",
    "model = mymodel()\n",
    "x = my.ones((2, 18))\n",
    "\n",
    "out = model(x)\n",
    "out.backward()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[448. 448. 496.]\n",
      "  [448. 448. 496.]]\n",
      "\n",
      " [[448. 448. 496.]\n",
      "  [448. 448. 496.]]\n",
      "\n",
      " [[448. 448. 496.]\n",
      "  [448. 448. 496.]]\n",
      "\n",
      " [[448. 448. 496.]\n",
      "  [448. 448. 496.]]]\n",
      "[[512.]\n",
      " [512.]\n",
      " [512.]\n",
      " [512.]]\n",
      "[[[264. 272. 288.]\n",
      "  [264. 272. 288.]\n",
      "  [264. 272. 288.]\n",
      "  [264. 272. 288.]]\n",
      "\n",
      " [[264. 272. 288.]\n",
      "  [264. 272. 288.]\n",
      "  [264. 272. 288.]\n",
      "  [264. 272. 288.]]\n",
      "\n",
      " [[264. 272. 288.]\n",
      "  [264. 272. 288.]\n",
      "  [264. 272. 288.]\n",
      "  [264. 272. 288.]]\n",
      "\n",
      " [[264. 272. 288.]\n",
      "  [264. 272. 288.]\n",
      "  [264. 272. 288.]\n",
      "  [264. 272. 288.]]]\n",
      "[[52.]\n",
      " [52.]\n",
      " [52.]\n",
      " [52.]]\n",
      "[[[268. 288. 281.]\n",
      "  [268. 288. 281.]\n",
      "  [268. 288. 281.]\n",
      "  [268. 288. 281.]]\n",
      "\n",
      " [[268. 288. 281.]\n",
      "  [268. 288. 281.]\n",
      "  [268. 288. 281.]\n",
      "  [268. 288. 281.]]\n",
      "\n",
      " [[268. 288. 281.]\n",
      "  [268. 288. 281.]\n",
      "  [268. 288. 281.]\n",
      "  [268. 288. 281.]]\n",
      "\n",
      " [[268. 288. 281.]\n",
      "  [268. 288. 281.]\n",
      "  [268. 288. 281.]\n",
      "  [268. 288. 281.]]]\n",
      "[[6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]]\n",
      "[[[1074. 1206. 1074.]\n",
      "  [1074. 1206. 1074.]\n",
      "  [1074. 1206. 1074.]\n",
      "  [1074. 1206. 1074.]]]\n",
      "[[3.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.l1.weight.grad)\n",
    "print(model.l1.bias.grad)\n",
    "print(model.l2.weight.grad)\n",
    "print(model.l2.bias.grad)\n",
    "print(model.l3.weight.grad)\n",
    "print(model.l3.bias.grad)\n",
    "print(model.l4.weight.grad)\n",
    "print(model.l4.bias.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(13419., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class mymodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Conv1d(2, 4, 3, 2, padding=2, bias=True)\n",
    "        self.l2 = nn.Conv1d(4, 4, 3, 2, padding=2, bias=True)\n",
    "        self.l3 = nn.Conv1d(4, 4, 3, 2, padding=2, bias=True)\n",
    "        self.l4 = nn.Conv1d(4, 1, 3, 2, padding=2, bias=True)\n",
    "    \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.children():\n",
    "            if isinstance(layer, nn.Conv1d):\n",
    "                nn.init.constant_(layer.weight, 1)  \n",
    "                if layer.bias is not None:\n",
    "                    nn.init.constant_(layer.bias, 1) \n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.l4(out)\n",
    "        print(out.shape)\n",
    "        return out.sum()\n",
    "    \n",
    "\n",
    "model = mymodel()\n",
    "x = torch.ones((2, 18))\n",
    "out = model(x)\n",
    "out.backward()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[448., 448., 496.],\n",
      "         [448., 448., 496.]],\n",
      "\n",
      "        [[448., 448., 496.],\n",
      "         [448., 448., 496.]],\n",
      "\n",
      "        [[448., 448., 496.],\n",
      "         [448., 448., 496.]],\n",
      "\n",
      "        [[448., 448., 496.],\n",
      "         [448., 448., 496.]]])\n",
      "tensor([512., 512., 512., 512.])\n",
      "tensor([[[264., 272., 288.],\n",
      "         [264., 272., 288.],\n",
      "         [264., 272., 288.],\n",
      "         [264., 272., 288.]],\n",
      "\n",
      "        [[264., 272., 288.],\n",
      "         [264., 272., 288.],\n",
      "         [264., 272., 288.],\n",
      "         [264., 272., 288.]],\n",
      "\n",
      "        [[264., 272., 288.],\n",
      "         [264., 272., 288.],\n",
      "         [264., 272., 288.],\n",
      "         [264., 272., 288.]],\n",
      "\n",
      "        [[264., 272., 288.],\n",
      "         [264., 272., 288.],\n",
      "         [264., 272., 288.],\n",
      "         [264., 272., 288.]]])\n",
      "tensor([52., 52., 52., 52.])\n",
      "tensor([[[268., 288., 281.],\n",
      "         [268., 288., 281.],\n",
      "         [268., 288., 281.],\n",
      "         [268., 288., 281.]],\n",
      "\n",
      "        [[268., 288., 281.],\n",
      "         [268., 288., 281.],\n",
      "         [268., 288., 281.],\n",
      "         [268., 288., 281.]],\n",
      "\n",
      "        [[268., 288., 281.],\n",
      "         [268., 288., 281.],\n",
      "         [268., 288., 281.],\n",
      "         [268., 288., 281.]],\n",
      "\n",
      "        [[268., 288., 281.],\n",
      "         [268., 288., 281.],\n",
      "         [268., 288., 281.],\n",
      "         [268., 288., 281.]]])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([[[1074., 1206., 1074.],\n",
      "         [1074., 1206., 1074.],\n",
      "         [1074., 1206., 1074.],\n",
      "         [1074., 1206., 1074.]]])\n",
      "tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "print(model.l1.weight.grad)\n",
    "print(model.l1.bias.grad)\n",
    "print(model.l2.weight.grad)\n",
    "print(model.l2.bias.grad)\n",
    "print(model.l3.weight.grad)\n",
    "print(model.l3.bias.grad)\n",
    "print(model.l4.weight.grad)\n",
    "print(model.l4.bias.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
