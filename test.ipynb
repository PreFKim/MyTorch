{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src as my"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 가능한 파라미터 선언 후, 연산 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2 = 5,5\n",
    "w1 = my.Param(1) \n",
    "w2 = my.Param(3) \n",
    "\n",
    "w3 = my.Param(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = x1*w1 \n",
    "out2 = w2*x2    \n",
    "out3 = out1+out2\n",
    "\n",
    "out4 = w3*out3 \n",
    "\n",
    "out5 = out4-5\n",
    "out6 = abs(out5/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.0, type:Node, foward_grad:[1], backward_grad:0.0 requrired_grad:True)(\n",
      "\t(19.0, type:Node, foward_grad:[0.2], backward_grad:0.0 requrired_grad:True)(\n",
      "\t\t(95, type:Node, foward_grad:[1], backward_grad:0.0 requrired_grad:True)(\n",
      "\t\t\t(100, type:Node, foward_grad:[20, 5], backward_grad:0.0 requrired_grad:True)(\n",
      "\t\t\t\t(5, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True)(\n",
      "\t\t\t\t)\n",
      "\t\t\t\t(20, type:Node, foward_grad:[1, 1], backward_grad:0.0 requrired_grad:True)(\n",
      "\t\t\t\t\t(5, type:Node, foward_grad:[5], backward_grad:0.0 requrired_grad:True)(\n",
      "\t\t\t\t\t\t(1, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True)(\n",
      "\t\t\t\t\t\t)\n",
      "\t\t\t\t\t)\n",
      "\t\t\t\t\t(15, type:Node, foward_grad:[5], backward_grad:0.0 requrired_grad:True)(\n",
      "\t\t\t\t\t\t(3, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True)(\n",
      "\t\t\t\t\t\t)\n",
      "\t\t\t\t\t)\n",
      "\t\t\t\t)\n",
      "\t\t\t)\n",
      "\t\t)\n",
      "\t)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "out6.print_node()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 역전파 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2 = 5,5\n",
    "w1 = my.Param(1) \n",
    "w2 = my.Param(3) \n",
    "\n",
    "w3 = my.Param(5)\n",
    "\n",
    "out1 = x1*w1 \n",
    "out2 = w2*x2    \n",
    "out3 = out1+out2\n",
    "\n",
    "out4 = w3*out3 \n",
    "\n",
    "out5 = out4-5\n",
    "out6 = abs(out5/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.0, type:Node, foward_grad:[1], backward_grad:0.0 requrired_grad:True)(\n",
      "\t(19.0, type:Node, foward_grad:[0.2], backward_grad:1.0 requrired_grad:True)(\n",
      "\t\t(95, type:Node, foward_grad:[1], backward_grad:0.2 requrired_grad:True)(\n",
      "\t\t\t(100, type:Node, foward_grad:[20, 5], backward_grad:0.2 requrired_grad:True)(\n",
      "\t\t\t\t(5, type:Param, foward_grad:[], backward_grad:4.0 requrired_grad:True)(\n",
      "\t\t\t\t)\n",
      "\t\t\t\t(20, type:Node, foward_grad:[1, 1], backward_grad:1.0 requrired_grad:True)(\n",
      "\t\t\t\t\t(5, type:Node, foward_grad:[5], backward_grad:1.0 requrired_grad:True)(\n",
      "\t\t\t\t\t\t(1, type:Param, foward_grad:[], backward_grad:5.0 requrired_grad:True)(\n",
      "\t\t\t\t\t\t)\n",
      "\t\t\t\t\t)\n",
      "\t\t\t\t\t(15, type:Node, foward_grad:[5], backward_grad:1.0 requrired_grad:True)(\n",
      "\t\t\t\t\t\t(3, type:Param, foward_grad:[], backward_grad:5.0 requrired_grad:True)(\n",
      "\t\t\t\t\t\t)\n",
      "\t\t\t\t\t)\n",
      "\t\t\t\t)\n",
      "\t\t\t)\n",
      "\t\t)\n",
      "\t)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "out6.backward()\n",
    "out6.print_node()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구현 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(my.layers.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = my.layers.Linear(in_channels=2,out_channels=2,bias=True)\n",
    "        self.l2 = my.layers.Linear(in_channels=2,out_channels=1,bias=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mymodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, type:Node, foward_grad:[1, 1], backward_grad:0.0 requrired_grad:True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([1,1]) #연산 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.parameters()) == ((2*2+2)+(2*1+1)) # 파라미터 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, type:Param, foward_grad:[], backward_grad:1.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:1.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:1.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:1.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:1.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:1.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:3.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:3.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:1.0 requrired_grad:True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = abs(model([1,1])[0]-6)\n",
    "loss.backward()\n",
    "model.parameters() # backward 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(my.layers.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = my.layers.Linear(2,4)\n",
    "        self.l2 = my.layers.Linear(4,4)\n",
    "        self.l3 = my.layers.Linear(4,4)\n",
    "        self.l4 = my.layers.Linear(4,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.l4(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mymodel()\n",
    "optim = my.optimizers.Origin(params=model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n",
      "(nan, type:Node, foward_grad:[nan], backward_grad:0.0 requrired_grad:True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(nan, type:Node, foward_grad:[1, 1], backward_grad:0.0 requrired_grad:True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y=x 함수 학습\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "\n",
    "        x = [j,j]\n",
    "        out = model(x)\n",
    "        loss = (out[0]-j)**2\n",
    "        loss.backward()\n",
    "        optim.update()\n",
    "        optim.zero_grad()\n",
    "    if (i%10==0):\n",
    "        print(loss)  \n",
    "print(loss)\n",
    "model([1000,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mymodel()\n",
    "optim = my.optimizers.Adam(params=model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28392953.942813262, type:Node, foward_grad:[10657.007824490562], backward_grad:0.0 requrired_grad:True)\n",
      "(2910155.248603306, type:Node, foward_grad:[3411.8354289756157], backward_grad:0.0 requrired_grad:True)\n",
      "(984042.1070058369, type:Node, foward_grad:[1983.9779303266828], backward_grad:0.0 requrired_grad:True)\n",
      "(404247.57563529804, type:Node, foward_grad:[1271.6093356613862], backward_grad:0.0 requrired_grad:True)\n",
      "(176591.36246399255, type:Node, foward_grad:[840.4555014133527], backward_grad:0.0 requrired_grad:True)\n",
      "(77707.32897603691, type:Node, foward_grad:[557.5206865257536], backward_grad:0.0 requrired_grad:True)\n",
      "(33242.2808729074, type:Node, foward_grad:[364.6493157701377], backward_grad:0.0 requrired_grad:True)\n",
      "(13350.488210161979, type:Node, foward_grad:[231.0886255111833], backward_grad:0.0 requrired_grad:True)\n",
      "(4807.377118729446, type:Node, foward_grad:[138.67050326193305], backward_grad:0.0 requrired_grad:True)\n",
      "(1444.2923093804327, type:Node, foward_grad:[76.00769196286473], backward_grad:0.0 requrired_grad:True)\n",
      "(379.09071541886004, type:Node, foward_grad:[38.940504127135284], backward_grad:0.0 requrired_grad:True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1198.4467867958494, type:Node, foward_grad:[1, 1], backward_grad:0.0 requrired_grad:True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y=x 함수 학습\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "\n",
    "        x = [j,j]\n",
    "        out = model(x)\n",
    "        loss = (out[0]-j)**2\n",
    "        loss.backward()\n",
    "        optim.update()\n",
    "        optim.zero_grad()\n",
    "    if (i%10==0):\n",
    "        print(loss)  \n",
    "print(loss)\n",
    "model([1000,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비선형 함수 구현 후 기능 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5, type:Node, foward_grad:[0.25], backward_grad:0.0 requrired_grad:True)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    ret = []\n",
    "    for p in x:\n",
    "        ret.append(1/(1+np.exp(1)**p))\n",
    "    return ret\n",
    "\n",
    "sigmoid([my.Param(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True),\n",
       " (0, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    ret = []\n",
    "    for p in x:\n",
    "        if p.data>0 : ret.append(p)\n",
    "        else : ret.append(my.Param(0))\n",
    "    return ret\n",
    "\n",
    "relu([my.Param(-1),my.Param(0),my.Param(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(my.layers.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = my.layers.Linear(2,4)\n",
    "        self.l2 = my.layers.Linear(4,4)\n",
    "        self.l3 = my.layers.Linear(4,4)\n",
    "        self.l4 = my.layers.Linear(4,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = relu(out)\n",
    "        out = self.l3(out)\n",
    "        out = relu(out)\n",
    "        out = self.l4(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mymodel()\n",
    "optim = my.optimizers.Adam(params=model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28392953.942813262, type:Node, foward_grad:[10657.007824490562], backward_grad:0.0 requrired_grad:True)\n",
      "(2910155.248603306, type:Node, foward_grad:[3411.8354289756157], backward_grad:0.0 requrired_grad:True)\n",
      "(984042.1070058369, type:Node, foward_grad:[1983.9779303266828], backward_grad:0.0 requrired_grad:True)\n",
      "(404247.57563529804, type:Node, foward_grad:[1271.6093356613862], backward_grad:0.0 requrired_grad:True)\n",
      "(176591.36246399255, type:Node, foward_grad:[840.4555014133527], backward_grad:0.0 requrired_grad:True)\n",
      "(77707.32897603691, type:Node, foward_grad:[557.5206865257536], backward_grad:0.0 requrired_grad:True)\n",
      "(33242.2808729074, type:Node, foward_grad:[364.6493157701377], backward_grad:0.0 requrired_grad:True)\n",
      "(13350.488210161979, type:Node, foward_grad:[231.0886255111833], backward_grad:0.0 requrired_grad:True)\n",
      "(4807.377118729446, type:Node, foward_grad:[138.67050326193305], backward_grad:0.0 requrired_grad:True)\n",
      "(1444.2923093804327, type:Node, foward_grad:[76.00769196286473], backward_grad:0.0 requrired_grad:True)\n",
      "(379.09071541886004, type:Node, foward_grad:[38.940504127135284], backward_grad:0.0 requrired_grad:True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1198.4467867958494, type:Node, foward_grad:[1, 1], backward_grad:0.0 requrired_grad:True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y=x 함수 학습\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "\n",
    "        x = [j,j]\n",
    "        out = model(x)\n",
    "        loss = (out[0]-j)**2\n",
    "        loss.backward()\n",
    "        optim.update()\n",
    "        optim.zero_grad()\n",
    "    if (i%10==0):\n",
    "        print(loss)  \n",
    "print(loss)\n",
    "model([1000,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# He Initialize 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True),\n",
       " (0, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True),\n",
       " (1, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    ret = []\n",
    "    for p in x:\n",
    "        if p.data>0 : ret.append(p)\n",
    "        else : ret.append(my.Param(0))\n",
    "    return ret\n",
    "\n",
    "relu([my.Param(-1),my.Param(0),my.Param(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(my.layers.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = my.layers.Linear(2,4)\n",
    "        self.l2 = my.layers.Linear(4,4)\n",
    "        self.l3 = my.layers.Linear(4,4)\n",
    "        self.l4 = my.layers.Linear(4,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = relu(out)\n",
    "        out = self.l3(out)\n",
    "        out = relu(out)\n",
    "        out = self.l4(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mymodel()\n",
    "optim = my.optimizers.Adam(params=model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0001297369189597024, type:Node, foward_grad:[-0.022780423082963352], backward_grad:0.0 requrired_grad:True)\n",
      "(6.5381051942209705e-09, type:Node, foward_grad:[0.00016171710106505088], backward_grad:0.0 requrired_grad:True)\n",
      "(5.175045772967522e-07, type:Node, foward_grad:[-0.001438755819862081], backward_grad:0.0 requrired_grad:True)\n",
      "(1.3163121106755372e-06, type:Node, foward_grad:[-0.0022946129178365027], backward_grad:0.0 requrired_grad:True)\n",
      "(0.006282458515775991, type:Node, foward_grad:[-0.15852392268394055], backward_grad:0.0 requrired_grad:True)\n",
      "(0.0019053371026805286, type:Node, foward_grad:[-0.0873003345395773], backward_grad:0.0 requrired_grad:True)\n",
      "(2.888871973827144e-07, type:Node, foward_grad:[-0.001074964552685742], backward_grad:0.0 requrired_grad:True)\n",
      "(6.396952463067362e-07, type:Node, foward_grad:[-0.0015996190125235898], backward_grad:0.0 requrired_grad:True)\n",
      "(4.173144345114406e-05, type:Node, foward_grad:[-0.012919975766408243], backward_grad:0.0 requrired_grad:True)\n",
      "(1.4884254316679253e-06, type:Node, foward_grad:[-0.0024400208455404027], backward_grad:0.0 requrired_grad:True)\n",
      "(4.5256325151651626e-07, type:Node, foward_grad:[-0.0013454564303856387], backward_grad:0.0 requrired_grad:True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(999.2014875473326, type:Node, foward_grad:[1, 1], backward_grad:0.0 requrired_grad:True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y=x 함수 학습\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "\n",
    "        x = [j,j]\n",
    "        out = model(x)\n",
    "        loss = (out[0]-j)**2\n",
    "        loss.backward()\n",
    "        optim.update()\n",
    "        optim.zero_grad()\n",
    "    if (i%10==0):\n",
    "        print(loss)  \n",
    "print(loss)\n",
    "model([1000,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy 상속후 할당,연산 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[(0.0, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True),\n",
       "         (0.0, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True)]],\n",
       "       dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.zeros((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[(1.0, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True),\n",
       "         (1.0, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True)]],\n",
       "       dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.ones((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([(1, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True),\n",
       "        (3, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True)],\n",
       "       dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.tensor([1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3]),\n",
       " Tensor([(1, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True),\n",
       "         (3, type:Param, foward_grad:[], backward_grad:0.0 requrired_grad:True)],\n",
       "        dtype=object))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr = np.array([1,3])\n",
    "np_arr, my.from_numpy(np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 관련 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor([(7.0, type:Node, foward_grad:[1, 1], backward_grad:28.0 requrired_grad:True),\n",
       "         (7.0, type:Node, foward_grad:[1, 1], backward_grad:28.0 requrired_grad:True)],\n",
       "        dtype=object),\n",
       " Tensor((196.0, type:Node, foward_grad:[28.0], backward_grad:0.0 requrired_grad:True),\n",
       "        dtype=object),\n",
       " Tensor([[(1.0, type:Param, foward_grad:[], backward_grad:28.0 requrired_grad:True),\n",
       "          (1.0, type:Param, foward_grad:[], backward_grad:28.0 requrired_grad:True)],\n",
       "         [(1.0, type:Param, foward_grad:[], backward_grad:56.0 requrired_grad:True),\n",
       "          (1.0, type:Param, foward_grad:[], backward_grad:56.0 requrired_grad:True)],\n",
       "         [(1.0, type:Param, foward_grad:[], backward_grad:84.0 requrired_grad:True),\n",
       "          (1.0, type:Param, foward_grad:[], backward_grad:84.0 requrired_grad:True)]],\n",
       "        dtype=object),\n",
       " Tensor([(1.0, type:Param, foward_grad:[], backward_grad:28.0 requrired_grad:True),\n",
       "         (1.0, type:Param, foward_grad:[], backward_grad:28.0 requrired_grad:True)],\n",
       "        dtype=object))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연산 및 역전파 테스트\n",
    "x = my.tensor([1,2,3])\n",
    "w = my.ones((3,2))\n",
    "b = my.ones((2))\n",
    "out1 = x@w+b\n",
    "out2 = out1.sum()**2\n",
    "out2.backward()\n",
    "out1,out2,w,b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor([[(0.9990000000000001, type:Param, foward_grad:[], backward_grad:28.0 requrired_grad:True),\n",
       "          (0.9990000000000001, type:Param, foward_grad:[], backward_grad:28.0 requrired_grad:True)],\n",
       "         [(0.999, type:Param, foward_grad:[], backward_grad:56.0 requrired_grad:True),\n",
       "          (0.999, type:Param, foward_grad:[], backward_grad:56.0 requrired_grad:True)],\n",
       "         [(0.999, type:Param, foward_grad:[], backward_grad:84.0 requrired_grad:True),\n",
       "          (0.999, type:Param, foward_grad:[], backward_grad:84.0 requrired_grad:True)]],\n",
       "        dtype=object),\n",
       " Tensor([(0.9990000000000001, type:Param, foward_grad:[], backward_grad:28.0 requrired_grad:True),\n",
       "         (0.9990000000000001, type:Param, foward_grad:[], backward_grad:28.0 requrired_grad:True)],\n",
       "        dtype=object))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 업데이트 확인\n",
    "optim = my.optimizers.Adam(w.parameters()+b.parameters())\n",
    "optim.update()\n",
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor([[(0.9990000000000001, type:Param, foward_grad:[], backward_grad:0 requrired_grad:True),\n",
       "          (0.9990000000000001, type:Param, foward_grad:[], backward_grad:0 requrired_grad:True)],\n",
       "         [(0.999, type:Param, foward_grad:[], backward_grad:0 requrired_grad:True),\n",
       "          (0.999, type:Param, foward_grad:[], backward_grad:0 requrired_grad:True)],\n",
       "         [(0.999, type:Param, foward_grad:[], backward_grad:0 requrired_grad:True),\n",
       "          (0.999, type:Param, foward_grad:[], backward_grad:0 requrired_grad:True)]],\n",
       "        dtype=object),\n",
       " Tensor([(0.9990000000000001, type:Param, foward_grad:[], backward_grad:0 requrired_grad:True),\n",
       "         (0.9990000000000001, type:Param, foward_grad:[], backward_grad:0 requrired_grad:True)],\n",
       "        dtype=object))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero_grad 확인\n",
    "optim.zero_grad()\n",
    "w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 Tensor 파라미터 인식 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class m(my.layers.Module):\n",
    "    def __init__(self):\n",
    "        self.w = my.ones((3,2))\n",
    "        self.b = my.ones((2))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return x @ self.w + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = m()\n",
    "len(model.parameters())==(3*2+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비교 연산자 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.Param(5) == 5, my.Param(5) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my.Param(5) != 5, my.Param(5) != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, False)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.Param(5) < 10, my.Param(5) < 5, my.Param(5) < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.Param(5) <= 10, my.Param(5) <= 5, my.Param(5) <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, True)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.Param(5) > 10, my.Param(5) > 5, my.Param(5) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, True)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.Param(5) >= 10, my.Param(5) >= 5, my.Param(5) >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([False,  True, False])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.tensor([1,2,3])==2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array 학습 테스트(배치, 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    mul = my.ones(x.shape)\n",
    "    mul[x<=0] = 0\n",
    "    x = x*mul\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(my.layers.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = my.layers.Linear(2,4)\n",
    "        self.l2 = my.layers.Linear(4,4)\n",
    "        self.l3 = my.layers.Linear(4,4)\n",
    "        self.l4 = my.layers.Linear(4,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = relu(out)\n",
    "        out = self.l3(out)\n",
    "        out = relu(out)\n",
    "        out = self.l4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409.391967542621, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(1191.5899865846895, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(999.6861386726109, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(891.3329814917455, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(825.7740533136509, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(791.4472742775564, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(776.221768638775, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(770.6403842928246, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(768.9526734790908, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(768.4580269435377, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n",
      "(768.2294925950029, type:Node, foward_grad:[0.01], backward_grad:0.0 requrired_grad:True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor([(861.4337176092436, type:Node, foward_grad:[1, 1], backward_grad:0.0 requrired_grad:True)],\n",
       "       dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = my.tensor([list(range(100)),list(range(100))]).reshape(-1,2)\n",
    "y = my.tensor([list(range(100))]).reshape(-1,1)\n",
    "model = mymodel()\n",
    "optim = my.optimizers.Adam(params=model.parameters(),lr=1e-3)\n",
    "# y=x 함수 학습\n",
    "for i in range(100):\n",
    "    out = model(x)\n",
    "    loss = ((out-y)**2).mean()\n",
    "    loss.backward()\n",
    "    optim.update()\n",
    "    optim.zero_grad()\n",
    "    if (i%10==0):\n",
    "        print(loss)  \n",
    "print(loss)\n",
    "model([1000,1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
